{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       I d e n t i f i e s   u n i q u e   o p p o r ...\n",
       "1       I d e n t i f i e s   u n i q u e   o p p o r ...\n",
       "2       Data Scientist   Curtin Teaching and Learning ...\n",
       "3       P r e f e r   c a n d i d a t e s   w i t h   ...\n",
       "4       P e r f o r m   a n d   i n t e r p r e t   d ...\n",
       "5       Data Scientist Data & Analytics - Sydney, New ...\n",
       "6       P r e f e r   c a n d i d a t e s   w i t h   ...\n",
       "7       P r e f e r   c a n d i d a t e s   w i t h   ...\n",
       "8       E q u i p   t h e   t e a m   w i t h   a   s ...\n",
       "9       D a t a   A s s e m b l y   &   A n a l y s i ...\n",
       "10      Data Scientist Brisbane Do you like big data? ...\n",
       "11      Y o u   b u i l d   a n d   e v a l u a t e   ...\n",
       "12      You will be working in an Agile methodology en...\n",
       "13        I m m e d i a t e   s t a r t   f o r   t h ...\n",
       "14      The Predictive Analytics Data Scientist provid...\n",
       "15        A p p l i a n c e s   a n d   P l a t f o r ...\n",
       "16      E q u i p   t h e   t e a m   w i t h   a   s ...\n",
       "17      3 - 5   y e a r s   e x p e r i e n c e   d e ...\n",
       "18      U n d e r s t a n d   t h e   b u s i n e s s ...\n",
       "19      P o s s e s s   5   y e a r s   o f   d a t a ...\n",
       "20      P o s s e s s   5   y e a r s   o f   d a t a ...\n",
       "21      They provide high quality, cost-effective stra...\n",
       "22      Listing Info Job Description The Predictive An...\n",
       "23      O p t i m i z e   t h e   a c c u r a c y   a ...\n",
       "24      1 0 +   e x p e r i e n c e   i n   a d v a n ...\n",
       "25      D e v e l o p   a p p l i c a t i o n s a n d ...\n",
       "26      D e v e l o p i n g   a   s t r a t e g y   a ...\n",
       "27      D e s i g n   a n d   p r o v i d e   g u i d ...\n",
       "28      You will be working in an Agile methodology en...\n",
       "29      You will be working in an Agile methodology en...\n",
       "                              ...                        \n",
       "1755    B S   o r   M S   i n   C o m p u t e r   S c ...\n",
       "1756    W e   a r e   A l t e r n a t i v e   C o n s ...\n",
       "1757    Apply for Lead JavaScript Developer  Up to 75,...\n",
       "1758    The Teradata Unified Data Architecture (UDA) p...\n",
       "1759    T r a n s l a t e   c o m p l e x   d a t a   ...\n",
       "1760    W e   a r e   A l t e r n a t i v e   C o n s ...\n",
       "1761    Descripcin de la oferta   Duracin de la oferta...\n",
       "1762      1 .   W e   a r e   A l t e r n a t i v e   ...\n",
       "1763      S o m o s   A l t e r n a t i v e   C o n s ...\n",
       "1764    Our employees' revolutionary ideas impact ever...\n",
       "1765      W e   a r e   A l t e r n a t i v e   C o n ...\n",
       "1766    At Pivotal, our mission is to enable customers...\n",
       "1767                                                  NaN\n",
       "1768    L e a d s   d a t a   m a n a g e m e n t   r ...\n",
       "1769    R o l e : P e r m a n e n t   L o c a t i o n ...\n",
       "1770    L e a d i n g   t h e   d e s k   a n a l y s ...\n",
       "1771    The first 18 months you have the opportunity f...\n",
       "1772                                                  ...\n",
       "1773    We are seeking candidates for tenure-track  as...\n",
       "1774    P o s s i b i l i t y   h e l p i n g   t o   ...\n",
       "1775    Independently interacts with clients on increa...\n",
       "1776    R e s e a r c h   i n   c l o s e   c o l l a ...\n",
       "1777                                                  ...\n",
       "1778    W o r k   w i t h   m a r k e t i n g   a n a ...\n",
       "1779    E i n e n   s e h r   v e r l s s l i c h e n ...\n",
       "1780    Our employees' revolutionary ideas impact ever...\n",
       "1781    Listing Info Additional Location(s) or Informa...\n",
       "1782    Listing Info   PROJECT LEAD, KNOWLEDGE NETWORK...\n",
       "1783    E i n e n   s e h r   v e r l s s l i c h e n ...\n",
       "1784    E i n e n   s e h r   v e r l s s l i c h e n ...\n",
       "Name: job_description, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/all_df')\n",
    "df.job_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df[df['job_description'] != 'Data Extraction Failed']\n",
    "df = df.dropna()\n",
    "df = df.drop_duplicates(['company', 'job_description', 'job_title', 'location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def describe_results(v_job_desc, nmf_weights, nmf_features, words = 100):\n",
    "    \n",
    "    for job_desc_type, skill in enumerate(nmf_features):\n",
    "        print(\"\\nTopic number:%d\" % job_desc_type) \n",
    "        print(\" \".join([feature_words[i] for i in skill.argsort()[:-words - 1:-1]]))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "vectorizer = vectorizer.fit(df['job_description'])\n",
    "v_job_desc = vectorizer.transform(df['job_description']).todense()\n",
    "\n",
    "feature_words = vectorizer.get_feature_names()\n",
    "\n",
    "nmf = NMF(n_components=5)\n",
    "nmf_weights = nmf.fit_transform(v_job_desc)\n",
    "nmf_features = nmf.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic number:0\n",
      "data experience business skills analytics analysis ability team statistical learning science big strong working analytical models work knowledge modeling techniques machine mining large tools solutions new product technical develop predictive insights statistics development design advanced problems using complex algorithms teams time environment years systems high scientist build understanding sources management engineering driven quantitative sas research hadoop role communication customer programming including problem end results use required computer requirements responsibilities multiple like support scale able real marketing drive degree processing python model sql software key understand services technologies communicate solving preferred building projects help sets information structured world actionable language methods\n",
      "\n",
      "Topic number:1\n",
      "und der von sie mit die zu fr im oder wir auf ihre sowie das bei den data einem iquest uns ein wie eine zur kunden ist analyse sind entwicklung aus kenntnisse ihnen durch aufgaben sich als ber gute dem er daten sehr informatik erfahrungen arbeiten mathematik bi bereich statistik big zum online umfeld haben einen bewerbung management um neue technologien des bringen unter projekten unternehmen fhigkeiten datenanalyse inovex idealerweise eines unser sap analytische erste lsungen einer erfahrung studium implementierung ihr bieten projekte mining abgeschlossenes methoden beim interesse unserer informationen bitte scientist business konzeption team nutzen auch analysieren statistischen englischkenntnisse\n",
      "\n",
      "Topic number:2\n",
      "helped retailers marketplaces shopping regardless recommending personalization pioneer channel consumers commerce led helps increase sales engagement online expert relevant products customer technology marketing global customers better world teradata product new banking support solution applications real services impact understand enable grow based develop value management demonstrate teams scotiabank responsible business help job hands leading strategy work digital focused growing solve texas practicing caring ti instruments pre content supporting dna france employees communities semiconductor designs revenue account opportunities solutions healthcare improve class payments fast organization country deploying including serves power associate use local advertising markets demand day positioning pivotal coordinators usps enhanced\n",
      "\n",
      "Topic number:3\n",
      "experience data learning work machine years position python scientist need applicants cybercoders linkedin authorized today application email company subject jobid benefits java line apply recruiter considered salary sql looking year doing forward resume competitive executive receiving capital going programming mining hadoop website algorithms background degree statistics analysis plus science knowledge computer new phd using credit large matlab reasons qualifications criminal applicable strong card relational open equity languages big start hive great databases world qualified software field related medical scale environment package pig san read team source modeling industry hands spark dental growth vacation engineering employment compensation article inquiries based vision\n",
      "\n",
      "Topic number:4\n",
      "level 10 effectively senior solutions performance science conceive articulated tactical design thorough work prepare data briefings journeyman unfamiliar balancing hs contractor scrutinized briefing addressing competing personnel importance responding course difficult strategic timely government determine unit theoretical 20 national familiar proactively methods mission priorities novel collection domains evaluate appropriate methodologies products range consistent challenges demonstrated research existing manner lead extensive writing executive high applied projects considered related identify expert models driven algorithms problems complex strong skills summarize guidance statisticians results language provide develop experienced statistical leadership ml coding developing banking years project operations bachelor courses including global implementation add support application\n"
     ]
    }
   ],
   "source": [
    "describe_results(v_job_desc, nmf_weights, nmf_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'en'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect(\"results understand responsibilities applications improve key based experiments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datascience_desc = ['''Identifies unique opportunities to collect new data and mine existing data. Experience in disparate data sources and bridging \n",
    "various sources to create a market view that can be used as a proprietary source of market data. Experienced \n",
    "at leveraging both structured and unstructured data sources. Responsible for validation, quality control and \n",
    "integration of 3rd party data into systems ensuring cohesive, accurate reporting Designs new processes and is\n",
    "able to build large, complex data sets. Strategises new uses for data and its interaction with data design using \n",
    "a variety of techniques and applications across various data sources. Minimum 2-3 years experience supporting multiple \n",
    "business functions, preferably progressive responsibilities within an established analytics team across Enterprise \n",
    "Projects. Masters or other advanced degree in Statistics, Mathematics or a related quantitative discipline Experience\n",
    "with statistical methodologies and tools (R, SAS, SPSS, etc) and predictive modeling Experience with data \n",
    "visualisation tools such as Tableau and Qlikview Advanced knowledge of database technologies and SQL language \n",
    "for querying and manipulating datasets. Extensive exposure to data warehousing concepts including data integration\n",
    "and data warehouse objects. Ability to understand and apply data and data relationships across multiple sources and \n",
    "domains Excellent communication, and presentation skills a must. The ability to bridge the gap between data science\n",
    "and business management. Possesses both creative abilities and business knowledge. Ability to work under pressure and \n",
    "meet deadlines. Has strong organisational skills, is detail oriented, and a team player Someone with strong foundation\n",
    "in statistics and advanced marketing analytics.''']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.2204460492503131e-16"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Identifies unique opportunities to collect new data and mine existing data. Experience in disparate data sources and bridging various sources to create a market view that can be used as a proprietary source of market data. Experienced at leveraging both structured and unstructured data sources. Responsible for validation, quality control and integration of 3rd party data into systems ensuring cohesive, accurate reporting Designs new processes and is able to build large, complex data sets. Strategises new uses for data and its interaction with data design using a variety of techniques and applications across various data sources. Minimum 2-3 years experience supporting multiple business functions, preferably progressive responsibilities within an established analytics team across Enterprise Projects. Masters or other advanced degree in Statistics, Mathematics or a related quantitative discipline Experience with statistical methodologies and tools (R, SAS, SPSS, etc) and predictive modeling Experience with data visualisation tools such as Tableau and Qlikview Advanced knowledge of database technologies and SQL language for querying and manipulating datasets. Extensive exposure to data warehousing concepts including data integration and data warehouse objects. Ability to understand and apply data and data relationships across multiple sources and domains Excellent communication, and presentation skills a must. The ability to bridge the gap between data science and business management. Possesses both creative abilities and business knowledge. Ability to work under pressure and meet deadlines. Has strong organisational skills, is detail oriented, and a team player Someone with strong foundation in statistics and advanced marketing analytics.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_input = vectorizer.transform(datascience_desc).todense()\n",
    "cos = [] \n",
    "\n",
    "df['cosine_similarity'] = map(lambda x: cosine(x, v_input), v_job_desc)\n",
    "\n",
    "df=df.sort_values('cosine_similarity')\n",
    "df.[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1322, 10595)\n",
      "10595\n",
      "1322\n"
     ]
    }
   ],
   "source": [
    "for i in xrange()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic number:0\n",
      "data business analysis analytics sources sql reporting tools experience ability quality statistical database modeling sas sets develop advanced requirements skills models identify analytical excel tableau information understand management processes reports using knowledge work complex stakeholders large analyst techniques insights bi etl create warehouse needs big process analytic new analyze provide intelligence communicate warehousing multiple visualization mining degree use predictive strong interpret databases microsoft working issues ensure analyses statistics support users internal trends end solutions integration define queries understanding problem key team decisions hoc required organization metrics perform drive quantitative various including design results cleansing analysts systems teams transformation findings preferred\n",
      "**********************\n",
      "Topic number:1\n",
      "sales marketing client business clients customer analytics relationships team product digital media management teams solutions opportunities selling account new work key ability experience industry manage campaign customers build drive accounts strong revenue products partners campaigns advertising working managing track value salesforce deliver level technology company understanding online senior skills insights solution proven ensure support services ad strategic channel strategy develop performance market partner strategies executives success events enterprise executive mobile com operations building lead direct service role consulting day agency best engagement presentations delivery record projects time internal fast technical driven high provide web plan adobe including levels stakeholders development\n",
      "**********************\n",
      "Topic number:2\n",
      "learning machine experience science statistics data statistical python modeling research mining algorithms computer models mathematics analysis techniques predictive programming quantitative engineering phd problems language strong large field matlab applied plus product ability analytics degree skills analytical work java advanced related regression years languages optimization sas knowledge datasets methods spark hadoop tools new masters physics scikit using operations sets nlp math model following solving insights real preferred ph complex relevant retrieval working natural academic clustering scale processing world develop series proficiency hive sql problem modelling background engineers deep scala team mathematical economics including time learn analyses familiarity similar like visualization scipy\n",
      "**********************\n",
      "Topic number:3\n",
      "skills ability experience project development technical management work scientific support research analysis demonstrated design clinical knowledge communication strong required related team including process reports excellent regulatory years projects provide analytical environment chemistry systems written business preferred information software results quality requirements procedures cell internal processes issues problem multiple relevant effectively ensure functional laboratory verbal external methods application manage ms high field studies degree health biology documentation new solving experimental industry applications product testing review maintain study leadership perform writing cross drug develop training food expertise working activities database independently interpersonal assist bioinformatics based minimum critical technology highly solutions compliance oral\n",
      "**********************\n",
      "Topic number:4\n",
      "experience hadoop data big technologies development systems software java design years hive spark distributed working architecture solutions processing cloud computer pig strong science knowledge scale platform nosql mapreduce web sql understanding linux tools python engineering hbase hands building like agile etl plus source open aws technical developing environment code infrastructure frameworks scalable skills programming production storm using scripting kafka performance bs work unix ecosystem large databases integration build applications scala cassandra storage excellent related services languages implementation platforms team hdfs end solid application environments expert relational database designing good communication implement technology high real amazon testing oriented warehouse oracle mysql\n",
      "**********************\n"
     ]
    }
   ],
   "source": [
    "describe_results(v_job_desc, nmf_weights, nmf_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Incompatible dimension for X and Y matrices: X.shape[1] == 10595 while Y.shape[1] == 58",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-d8ddde0dd8e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_job_desc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/metrics/pairwise.pyc\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m    879\u001b[0m     \u001b[0;31m# to avoid recursive import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m     \u001b[0mX_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sklearn/metrics/pairwise.pyc\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed)\u001b[0m\n\u001b[1;32m    106\u001b[0m         raise ValueError(\"Incompatible dimension for X and Y matrices: \"\n\u001b[1;32m    107\u001b[0m                          \"X.shape[1] == %d while Y.shape[1] == %d\" % (\n\u001b[0;32m--> 108\u001b[0;31m                              X.shape[1], Y.shape[1]))\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Incompatible dimension for X and Y matrices: X.shape[1] == 10595 while Y.shape[1] == 58"
     ]
    }
   ],
   "source": [
    "similarity = cosine_similarity(v_job_desc, v_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('data/zip_data2')\n",
    "df = df[df['job_description'] != '[]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "from time import sleep\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrapying_selenium(url):\n",
    "    headers = {\"User-agent\":\"Mozilla/5.0 (X11; Linux x86_64) App√±leWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.80 Safari/537.36\"}\n",
    "    browser = webdriver.Chrome(\"/Applications/chromedriver\")\n",
    "    browser.set_page_load_timeout(5)\n",
    "    browser.get(url) #Connects to Website\n",
    "    soup = BeautifulSoup(browser.page_source)# Get the html from the site\n",
    "    browser.quit()\n",
    "    return soup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cleaning_site(website):\n",
    "    soup = scrapying_selenium(website)\n",
    "    job_descriptions = soup.findAll('div', class_=\"rich-text\")\n",
    "    jobs_desc =[]\n",
    "    for job_description in job_descriptions:\n",
    "        for job in job_description.findAll('li'):\n",
    "            jobs_desc.append(job.text)\n",
    "    return jobs_desc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "page = 49\n",
    "x = indeed_url + '&start=' + str((page-1)*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indeed_url = 'http://www.indeed.com/jobs?q=' + 'data+scientist' + '&l='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10%9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10%11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32%10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = (\n",
    "\"The sky is blue\",\n",
    "\"The sun is bright\",\n",
    "\"The sun in the sky is bright\",\n",
    "\"We can see the shining sun, the bright sun\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 11)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "print tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.36651513,  0.52305744,  0.13448867]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(tfidf_matrix[0:1], tfidf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x11 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 4 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "code = 'AF|AX|AL|DZ|AS|AD|AO|AI|AQ|AG|AR|AM|AW|AU|AT|AZ|BS|BH|BD|BB|BY|BE|BZ|BJ|BM|BT|BO|BA|BW|BV|BR|IO|BN|BG|BF|BI|KH|CM|CA|CV|KY|CF|TD|CL|CN|CX|CC|CO|KM|CG|CD|CK|CR|CI|HR|CU|CY|CZ|DK|DJ|DM|DO|EC|EG|SV|GQ|ER|EE|ET|FK|FO|FJ|FI|FR|GF|PF|TF|GA|GM|GE|DE|GH|GI|GR|GL|GD|GP|GU|GT|GN|GW|GY|HT|HM|VA|HN|HK|HU|IS|IN|ID|IR|IQ|IE|IL|IT|JM|JP|JO|KZ|KE|KI|KP|KR|KW|KG|LA|LV|LB|LS|LR|LY|LI|LT|LU|MO|MK|MG|MW|MY|MV|ML|MT|MH|MQ|MR|MU|YT|MX|FM|MD|MC|MN|MS|MA|MZ|MM|NA|NR|NP|NL|AN|NC|NZ|NI|NE|NG|NU|NF|MP|NO|OM|PK|PW|PS|PA|PG|PY|PE|PH|PN|PL|PT|PR|QA|RE|RO|RU|RW|SH|KN|LC|PM|VC|WS|SM|ST|SA|SN|CS|SC|SL|SG|SK|SI|SB|SO|ZA|GS|ES|LK|SD|SR|SJ|SZ|SE|CH|SY|TW|TJ|TZ|TH|TL|TG|TK|TO|TT|TN|TR|TM|TC|TV|UG|UA|AE|GB|US|UM|UY|UZ|VU|VE|VN|VG|VI|WF|EH|YE|ZM|ZW'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "code = str.lower(code)\n",
    "code2 = str.replace(code, '|', '\\',\\'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "code2 = ['af','ax','al','dz','as','ad','ao','ai','aq','ag','ar','am','aw','au','at','az','bs','bh','bd','bb','by','be','bz','bj','bm','bt','bo','ba','bw','bv','br','io','bn','bg','bf','bi','kh','cm','ca','cv','ky','cf','td','cl','cn','cx','cc','co','km','cg','cd','ck','cr','ci','hr','cu','cy','cz','dk','dj','dm','do','ec','eg','sv','gq','er','ee','et','fk','fo','fj','fi','fr','gf','pf','tf','ga','gm','ge','de','gh','gi','gr','gl','gd','gp','gu','gt','gn','gw','gy','ht','hm','va','hn','hk','hu','is','in','id','ir','iq','ie','il','it','jm','jp','jo','kz','ke','ki','kp','kr','kw','kg','la','lv','lb','ls','lr','ly','li','lt','lu','mo','mk','mg','mw','my','mv','ml','mt','mh','mq','mr','mu','yt','mx','fm','md','mc','mn','ms','ma','mz','mm','na','nr','np','nl','an','nc','nz','ni','ne','ng','nu','nf','mp','no','om','pk','pw','ps','pa','pg','py','pe','ph','pn','pl','pt','pr','qa','re','ro','ru','rw','sh','kn','lc','pm','vc','ws','sm','st','sa','sn','cs','sc','sl','sg','sk','si','sb','so','za','gs','es','lk','sd','sr','sj','sz','se','ch','sy','tw','tj','tz','th','tl','tg','tk','to','tt','tn','tr','tm','tc','tv','ug','ua','ae','gb','us','um','uy','uz','vu','ve','vn','vg','vi','wf','eh','ye','zm','zw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['af',\n",
       " 'ax',\n",
       " 'al',\n",
       " 'dz',\n",
       " 'as',\n",
       " 'ad',\n",
       " 'ao',\n",
       " 'ai',\n",
       " 'aq',\n",
       " 'ag',\n",
       " 'ar',\n",
       " 'am',\n",
       " 'aw',\n",
       " 'au',\n",
       " 'at',\n",
       " 'az',\n",
       " 'bs',\n",
       " 'bh',\n",
       " 'bd',\n",
       " 'bb',\n",
       " 'by',\n",
       " 'be',\n",
       " 'bz',\n",
       " 'bj',\n",
       " 'bm',\n",
       " 'bt',\n",
       " 'bo',\n",
       " 'ba',\n",
       " 'bw',\n",
       " 'bv',\n",
       " 'br',\n",
       " 'io',\n",
       " 'bn',\n",
       " 'bg',\n",
       " 'bf',\n",
       " 'bi',\n",
       " 'kh',\n",
       " 'cm',\n",
       " 'ca',\n",
       " 'cv',\n",
       " 'ky',\n",
       " 'cf',\n",
       " 'td',\n",
       " 'cl',\n",
       " 'cn',\n",
       " 'cx',\n",
       " 'cc',\n",
       " 'co',\n",
       " 'km',\n",
       " 'cg',\n",
       " 'cd',\n",
       " 'ck',\n",
       " 'cr',\n",
       " 'ci',\n",
       " 'hr',\n",
       " 'cu',\n",
       " 'cy',\n",
       " 'cz',\n",
       " 'dk',\n",
       " 'dj',\n",
       " 'dm',\n",
       " 'do',\n",
       " 'ec',\n",
       " 'eg',\n",
       " 'sv',\n",
       " 'gq',\n",
       " 'er',\n",
       " 'ee',\n",
       " 'et',\n",
       " 'fk',\n",
       " 'fo',\n",
       " 'fj',\n",
       " 'fi',\n",
       " 'fr',\n",
       " 'gf',\n",
       " 'pf',\n",
       " 'tf',\n",
       " 'ga',\n",
       " 'gm',\n",
       " 'ge',\n",
       " 'de',\n",
       " 'gh',\n",
       " 'gi',\n",
       " 'gr',\n",
       " 'gl',\n",
       " 'gd',\n",
       " 'gp',\n",
       " 'gu',\n",
       " 'gt',\n",
       " 'gn',\n",
       " 'gw',\n",
       " 'gy',\n",
       " 'ht',\n",
       " 'hm',\n",
       " 'va',\n",
       " 'hn',\n",
       " 'hk',\n",
       " 'hu',\n",
       " 'is',\n",
       " 'in',\n",
       " 'id',\n",
       " 'ir',\n",
       " 'iq',\n",
       " 'ie',\n",
       " 'il',\n",
       " 'it',\n",
       " 'jm',\n",
       " 'jp',\n",
       " 'jo',\n",
       " 'kz',\n",
       " 'ke',\n",
       " 'ki',\n",
       " 'kp',\n",
       " 'kr',\n",
       " 'kw',\n",
       " 'kg',\n",
       " 'la',\n",
       " 'lv',\n",
       " 'lb',\n",
       " 'ls',\n",
       " 'lr',\n",
       " 'ly',\n",
       " 'li',\n",
       " 'lt',\n",
       " 'lu',\n",
       " 'mo',\n",
       " 'mk',\n",
       " 'mg',\n",
       " 'mw',\n",
       " 'my',\n",
       " 'mv',\n",
       " 'ml',\n",
       " 'mt',\n",
       " 'mh',\n",
       " 'mq',\n",
       " 'mr',\n",
       " 'mu',\n",
       " 'yt',\n",
       " 'mx',\n",
       " 'fm',\n",
       " 'md',\n",
       " 'mc',\n",
       " 'mn',\n",
       " 'ms',\n",
       " 'ma',\n",
       " 'mz',\n",
       " 'mm',\n",
       " 'na',\n",
       " 'nr',\n",
       " 'np',\n",
       " 'nl',\n",
       " 'an',\n",
       " 'nc',\n",
       " 'nz',\n",
       " 'ni',\n",
       " 'ne',\n",
       " 'ng',\n",
       " 'nu',\n",
       " 'nf',\n",
       " 'mp',\n",
       " 'no',\n",
       " 'om',\n",
       " 'pk',\n",
       " 'pw',\n",
       " 'ps',\n",
       " 'pa',\n",
       " 'pg',\n",
       " 'py',\n",
       " 'pe',\n",
       " 'ph',\n",
       " 'pn',\n",
       " 'pl',\n",
       " 'pt',\n",
       " 'pr',\n",
       " 'qa',\n",
       " 're',\n",
       " 'ro',\n",
       " 'ru',\n",
       " 'rw',\n",
       " 'sh',\n",
       " 'kn',\n",
       " 'lc',\n",
       " 'pm',\n",
       " 'vc',\n",
       " 'ws',\n",
       " 'sm',\n",
       " 'st',\n",
       " 'sa',\n",
       " 'sn',\n",
       " 'cs',\n",
       " 'sc',\n",
       " 'sl',\n",
       " 'sg',\n",
       " 'sk',\n",
       " 'si',\n",
       " 'sb',\n",
       " 'so',\n",
       " 'za',\n",
       " 'gs',\n",
       " 'es',\n",
       " 'lk',\n",
       " 'sd',\n",
       " 'sr',\n",
       " 'sj',\n",
       " 'sz',\n",
       " 'se',\n",
       " 'ch',\n",
       " 'sy',\n",
       " 'tw',\n",
       " 'tj',\n",
       " 'tz',\n",
       " 'th',\n",
       " 'tl',\n",
       " 'tg',\n",
       " 'tk',\n",
       " 'to',\n",
       " 'tt',\n",
       " 'tn',\n",
       " 'tr',\n",
       " 'tm',\n",
       " 'tc',\n",
       " 'tv',\n",
       " 'ug',\n",
       " 'ua',\n",
       " 'ae',\n",
       " 'gb',\n",
       " 'us',\n",
       " 'um',\n",
       " 'uy',\n",
       " 'uz',\n",
       " 'vu',\n",
       " 've',\n",
       " 'vn',\n",
       " 'vg',\n",
       " 'vi',\n",
       " 'wf',\n",
       " 'eh',\n",
       " 'ye',\n",
       " 'zm',\n",
       " 'zw']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
